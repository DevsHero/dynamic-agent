# This file provides example environment variables for the Dynamic Agent application.
# Copy this to .env and modify as needed for your environment.

# --- History Store Args ---
# History chat store type (redis, qdrant, memory)
HISTORY_TYPE=redis
# History chat store host endpoint (e.g., redis://127.0.0.1:6379 for Redis, http://127.0.0.1:6334 for Qdrant)
HISTORY_HOST=redis://127.0.0.1:6379
# Prefix for Redis history keys.
HISTORY_REDIS_PREFIX=history:
# Batch size for Redis SCAN command when listing history.
HISTORY_REDIS_SCAN_COUNT=100

# --- Chat LLM Provider Args ---
# Type of LLM provider for chat completion (e.g., ollama, openai, anthropic, gemini, deepseek, groq, xai)
CHAT_LLM_TYPE=ollama
# Base URL for the Chat LLM provider API (e.g., http://localhost:11434 for Ollama). If not set, adapter-specific defaults may apply.
CHAT_BASE_URL="http://localhost:11434"
# API Key for the Chat LLM provider (e.g., OpenAI, Anthropic).
CHAT_API_KEY=""
# Model name for chat completion (e.g., gpt-4o, llama3, claude-3-opus-20240229). If not set, adapter-specific defaults may apply.
CHAT_MODEL="llama3"

# --- Embedding LLM Provider Args ---
# Type of LLM provider for text embedding (e.g., ollama, openai, anthropic, gemini, deepseek, groq, xai)
EMBEDDING_LLM_TYPE=ollama
# Base URL for the Embedding LLM provider API (e.g., http://localhost:11434 for Ollama). If not set, adapter-specific defaults may apply.
EMBEDDING_BASE_URL="http://localhost:11434"
# API Key for the Embedding LLM provider (e.g., OpenAI, Anthropic).
EMBEDDING_API_KEY=""
# Model name for text embedding (e.g., text-embedding-3-small, nomic-embed-text). If not set, adapter-specific defaults may apply.
EMBEDDING_MODEL="nomic-embed-text"

# --- Query Generation LLM Provider Args (Optional) ---
# Type of LLM provider for query generation. Defaults to CHAT_LLM_TYPE if not set.
QUERY_LLM_TYPE=
# Base URL for the Query Generation LLM provider API. Defaults to CHAT_BASE_URL if not set.
QUERY_BASE_URL=
# API Key for the Query Generation LLM provider. Defaults to CHAT_API_KEY if not set or if empty.
QUERY_API_KEY=
# Model name for query generation. Defaults to CHAT_MODEL if not set.
QUERY_MODEL=

# --- Vector Store Args ---
# Vector database type (redis, chroma, milvus, qdrant, surreal, pinecone)
VECTOR_TYPE=redis
# Vector database URL/host endpoint (e.g., redis://127.0.0.1:6379 for Redis, http://localhost:6334 for Qdrant)
VECTOR_HOST=redis://127.0.0.1:6379
# Enable authentication for the vector database (true/false)
VECTOR_AUTH=false
# Username for vector database authentication (Milvus, SurrealDB)
VECTOR_USER=root
# Password for vector database authentication (Milvus, SurrealDB, Redis)
VECTOR_PASS=
# API key/token for vector database authentication (Chroma, Qdrant, Pinecone)
VECTOR_SECRET=
# Target database name for vector store
VECTOR_DATABASE=default_database
# Index/Collection name for vector store (Pinecone, Chroma, Qdrant, etc.)
VECTOR_INDEX_NAME=default_index
# Tenant name for multi-tenant vector databases (Chroma)
VECTOR_TENANT=default_tenant
# Namespace for vector databases that support it (SurrealDB)
VECTOR_NAMESPACE=default_namespace
# Vector dimension size
VECTOR_DIMENSION=768
# Distance metric for vector similarity (l2, ip, cosine, euclidean, dotproduct)
VECTOR_METRIC=cosine

# --- Pinecone Specific Vector Args ---
# Cloud provider for Pinecone (aws, azure, gcp)
PINECONE_CLOUD=aws
# Cloud region for Pinecone (us-east-1, us-west-1, etc.)
PINECONE_REGION=us-east-1

# --- General App Args ---
# Auto generate/reload schema for the vector database on startup
AUTO_SCHEMA=false
# Enable debug logging/output
DEBUG=false
# Path to the vector store schema definition file.
SCHEMA_PATH=json/index_schema.json
# Path to the prompt configuration file.
PROMPTS_PATH=json/prompts.json
# Default number of results to retrieve in RAG queries.
RAG_DEFAULT_LIMIT=20
# Host address and port for the WebSocket server to listen on.
SERVER_ADDR=127.0.0.1:4000
# Directory containing vector store function schema definition files (e.g., qdrant.json, redis.json).
FUNCTION_SCHEMA_DIR=json/query
# Use an LLM to generate vector search queries that specify relevant fields.
# This can help reduce less relevant results but accuracy depends on LLM understanding.
LLM_QUERY=false

# --- WebSocket Server Auth ---
# Optional API Key required for clients to connect to the WebSocket server.
# If set, clients must provide this key via HMAC-based authentication.
SERVER_API_KEY=your_server_api_key_here

# --- Caching Layer (Redis + Qdrant) ---
# Enable caching layer (Redis exact match + Qdrant semantic match).
ENABLE_CACHE=false
# Redis URL for the caching layer. Using a different DB (e.g., /1) is recommended to avoid collisions.
CACHE_REDIS_URL=redis://127.0.0.1:6379/1
# Qdrant URL for the semantic caching layer.
CACHE_QDRANT_URL=http://localhost:6334
# Optional API Key for the Qdrant cache instance.
CACHE_QDRANT_API_KEY=
# Qdrant collection name for caching prompts and responses.
CACHE_QDRANT_COLLECTION=prompt_response_cache
# Cosine similarity threshold for considering a Qdrant cache hit valid (0.0 to 1.0).
CACHE_SIMILARITY_THRESHOLD=0.5
# Time-to-live (TTL) in seconds for Redis cache entries. 0 means no TTL. (Default: 3600 = 1 hour)
CACHE_REDIS_TTL=3600

# --- TLS for WSS (Secure WebSocket) ---
# Enable TLS for the WebSocket server (WSS). Requires TLS_CERT_PATH and TLS_KEY_PATH to be set.
ENABLE_TLS=false
# Optional path to the TLS certificate file (PEM format).
TLS_CERT_PATH=
# Optional path to the TLS private key file (PEM format).
TLS_KEY_PATH=

# --- Remote Prompt Configuration ---
# Enable fetching prompt configurations from a remote source (e.g., Firebase Remote Config).
ENABLE_REMOTE_PROMPTS=false
# Project ID for the remote prompt configuration service (e.g., Firebase Project ID). Required if 'ENABLE_REMOTE_PROMPTS' is true.
REMOTE_PROMPTS_PROJECT_ID=your-firebase-project-id
# Path to the service account key JSON file for authenticating with the remote prompt configuration service. Required if 'ENABLE_REMOTE_PROMPTS' is true.
REMOTE_PROMPTS_SA_KEY_PATH=firebase-sa.json

# --- HTTP Webhook Server ---
# Port for HTTP webhook endpoints (e.g., for reloading prompts). Different from WebSocket port.
HTTP_PORT=4200

# --- Notes on Remote Prompts (Firebase Example) ---
# To use remote prompts with Firebase Remote Config:
# 1. Create a Firebase project and enable the Remote Config service.
# 2. In Remote Config, define parameters (e.g., "prompts", "intents", "query_templates", "response_templates").
#    For each parameter:
#      - Set its "Value type" to "JSON".
#      - The "Default value" should be a JSON *string* that contains the actual JSON configuration for that category.
#        (e.g., for "prompts", the value would be a string like: "{\"system_message\": \"You are helpful.\"}" )
# 3. In Firebase Project Settings > Service Accounts, generate a new private key (JSON file).
# 4. Save this key file to the path specified in REMOTE_PROMPTS_SA_KEY_PATH (e.g., "firebase-sa.json").
# 5. Set ENABLE_REMOTE_PROMPTS=true and provide your REMOTE_PROMPTS_PROJECT_ID.
# 6. Use the /api/reload-prompts webhook to fetch updates.